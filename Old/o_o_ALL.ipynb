{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as prep\n",
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "import os\n",
    "from datetime import date, timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_window_ = 30 # days\n",
    "_train_test_split_ = 1.0\n",
    "\n",
    "_scaler_ = prep.MinMaxScaler() # StandardScaler()\n",
    "\n",
    "_loss_ = \"mean_squared_error\"\n",
    "_optimizer_ = \"adam\" # rmsprop\n",
    "_batch_size_ = 768\n",
    "_epochs_ = 500\n",
    "_validation_split_ = 0.0\n",
    "\n",
    "_date_ = '20180518'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(layers[1], input_shape=(None, layers[0]), return_sequences=True))\n",
    "    model.add(LSTM(50, input_shape=(None, layers[1]), return_sequences=False))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    \n",
    "    model.compile(loss=_loss_, optimizer=_optimizer_, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X):\n",
    "    samples, nx, ny = X.shape\n",
    "    X = X.reshape((samples, nx * ny))\n",
    "    \n",
    "    scaler = _scaler_.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    return X.reshape((samples, nx, ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_backward(d, y):\n",
    "    if type(_scaler_) is prep.data.MinMaxScaler:\n",
    "        return y * (max(d) - min(d)) + min(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_toward(d, x):\n",
    "    if type(_scaler_) is prep.data.MinMaxScaler:\n",
    "        return (x - min(d)) / (max(d) - min(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, _column_):\n",
    "    feature_len = len(data.columns)\n",
    "    data = data.as_matrix()\n",
    "    \n",
    "    \"\"\"\n",
    "    e.g., _window_ = 3\n",
    "    0~3 1~4 2~5  result\n",
    "    0~2 1~3 2~4  X\n",
    "    3   4   5    y\n",
    "    \"\"\"\n",
    "    seq_len = _window_ + 1  ## _window_s + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - seq_len):\n",
    "        result.append(data[index : index + seq_len])\n",
    "        \n",
    "    result = np.array(result)\n",
    "    scaled_result = scale_data(result)\n",
    "    \n",
    "    row = round(_train_test_split_ * scaled_result.shape[0])\n",
    "#     train, test = scaled_result[:int(row)], scaled_result[int(row):]\n",
    "    train = scaled_result[:int(row)]\n",
    "\n",
    "    X_train = train[:, :-1, :]\n",
    "    y_train = train[:, -1, :][:, _column_]  ## change\n",
    "    \n",
    "#     X_test = test[:, :-1, :]\n",
    "#     y_test = test[:, -1, :][:, _column_]  ## change\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], feature_len))\n",
    "#     X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], feature_len))\n",
    "\n",
    "    return [X_train, y_train, _, _]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(pred, y):\n",
    "    plt2.figure()\n",
    "    plt2.plot(pred, color='red', label='Prediction')\n",
    "    plt2.plot(y, color='blue', label='Ground Truth')\n",
    "    plt2.legend()\n",
    "    plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ↓↓↓ __main__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_msg(now, last):\n",
    "    diff = float( format(now, '.2f') ) - float( format(last, '.2f') )    \n",
    "    if diff > 0:\n",
    "        return \"1\"  # 漲\n",
    "    elif diff < 0:\n",
    "        return \"-1\" # 跌\n",
    "    else:\n",
    "        return \"0\"\n",
    "\n",
    "def format_n_days(price):\n",
    "    output = str(_code_) + '\\t'\n",
    "    for i in range(0, 5 if len(price)>=5 else len(price)):\n",
    "        if i==0:\n",
    "            output += '{}\\t{:.2f}\\t'.format(show_msg(price[i], last), price[i])\n",
    "        else:\n",
    "            output += '{}\\t{:.2f}\\t'.format(show_msg(price[i], price[i-1]), price[i])\n",
    "    return output\n",
    "\n",
    "def TBrain_score(predict_str, real_str):\n",
    "    predict = predict_str.split('\\t')[1:-1]\n",
    "    real = real_str.split('\\t')[1:-1]\n",
    "\n",
    "    weights = [0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "\n",
    "    # (實際價格 – 絕對值(預測價格 – 實際價格)) /實際價格)*0.5\n",
    "    p_score = [\n",
    "        ( ( float(r) - abs(float(r) - float(p)) ) / float(r) ) * 0.5\n",
    "        for (r, p) in zip(real[1::2], predict[1::2]) \n",
    "    ]\n",
    "\n",
    "    # 預測正確得 0.5\n",
    "    q_score = [\n",
    "        0.5 if float(r) == float(p) else 0.0\n",
    "        for (r, p) in zip(real[0::2], predict[0::2])\n",
    "    ]\n",
    "\n",
    "    return sum([ p*w + q*w for (p, q, w) in zip(p_score, q_score, weights) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "bar = IntProgress(min=0, max=5*18)\n",
    "display(bar)\n",
    "\n",
    "df = pd.read_csv('/home/ddl/Desktop/Notebooks/TBrain/' + _date_ + '/taetfp.csv', thousands=',')\n",
    "\n",
    "for _code_ in df.代碼.unique():\n",
    "#     _code_ = 50\n",
    "    \n",
    "    bar.value = 0\n",
    "    data = df[df['代碼'] == _code_].sort_values(by='日期', ascending=False) \\\n",
    "                                    .drop(columns=['日期', '中文簡稱', '代碼'])\n",
    "    \n",
    "    # number of transactions\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(data, -1)\n",
    "    model_num = build_model([X_train.shape[2], _window_])\n",
    "    model_num.fit(X_train, y_train, batch_size=_batch_size_, epochs=_epochs_, validation_split=_validation_split_, verbose=0)\n",
    "    bar.value += 1\n",
    "    \n",
    "    # close price\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(data, -2)\n",
    "    model_close = build_model([X_train.shape[2], _window_])\n",
    "    model_close.fit(X_train, y_train, batch_size=_batch_size_, epochs=_epochs_, validation_split=_validation_split_, verbose=0)\n",
    "    bar.value += 1\n",
    "    \n",
    "    # low price\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(data, -3)\n",
    "    model_low = build_model([X_train.shape[2], _window_])\n",
    "    model_low.fit(X_train, y_train, batch_size=_batch_size_, epochs=_epochs_, validation_split=_validation_split_, verbose=0)\n",
    "    bar.value += 1\n",
    "    \n",
    "    # high price\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(data, -4)\n",
    "    model_high = build_model([X_train.shape[2], _window_])\n",
    "    model_high.fit(X_train, y_train, batch_size=_batch_size_, epochs=_epochs_, validation_split=_validation_split_, verbose=0)\n",
    "    bar.value += 1\n",
    "    \n",
    "    # open price\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(data, -5)\n",
    "    model_open = build_model([X_train.shape[2], _window_])\n",
    "    model_open.fit(X_train, y_train, batch_size=_batch_size_, epochs=_epochs_, validation_split=_validation_split_, verbose=0)\n",
    "    bar.value += 1\n",
    "    \n",
    "    # predict 5 days\n",
    "    o1, o2, o3, o4, o5 = [], [], [], [], []\n",
    "    pred = []\n",
    "\n",
    "    for i in range(0, 5):\n",
    "        dataArr = np.array(data)\n",
    "\n",
    "        if i == 0:\n",
    "            X = dataArr[:_window_]\n",
    "        else:\n",
    "            X = np.append(pred[::-1], dataArr[:_window_-i], axis=0)\n",
    "\n",
    "        X[:, 0] = scale_toward(list(dataArr[:, 0]) + o1, X[:, 0])\n",
    "        X[:, 1] = scale_toward(list(dataArr[:, 1]) + o2, X[:, 1])\n",
    "        X[:, 2] = scale_toward(list(dataArr[:, 2]) + o3, X[:, 2])\n",
    "        X[:, 3] = scale_toward(list(dataArr[:, 3]) + o4, X[:, 3])\n",
    "        X[:, 4] = scale_toward(list(dataArr[:, 4]) + o5, X[:, 4])\n",
    "\n",
    "        X = np.expand_dims(X, axis=0)\n",
    "\n",
    "        p = [\n",
    "            scale_backward(list(dataArr[:, 0]) + o1, model_open.predict(X)),\n",
    "            scale_backward(list(dataArr[:, 1]) + o2, model_high.predict(X)),\n",
    "            scale_backward(list(dataArr[:, 2]) + o3, model_low.predict(X)),\n",
    "            scale_backward(list(dataArr[:, 3]) + o4, model_close.predict(X)),\n",
    "            scale_backward(list(dataArr[:, 4]) + o5, model_num.predict(X))\n",
    "        ]\n",
    "\n",
    "        p = [float(j) for j in p]\n",
    "\n",
    "        o1 += [p[0]]\n",
    "        o2 += [p[1]]\n",
    "        o3 += [p[2]]\n",
    "        o4 += [p[3]]\n",
    "        o5 += [p[4]]\n",
    "        pred.append(p)\n",
    "    \n",
    "    \n",
    "    # print predict\n",
    "    last = np.array(data)[0][-2]\n",
    "    date = int(df[df['代碼'] == _code_].sort_values(by='日期', ascending=False).head(1).日期)\n",
    "    print(format_n_days(o4))\n",
    "    \n",
    "    # print real\n",
    "    real_date = (datetime.strptime(_date_, '%Y%m%d')  + timedelta(days=7)).strftime('%Y%m%d')\n",
    "    real_path = '/home/ddl/Desktop/Notebooks/TBrain/' + real_date + '/taetfp.csv'\n",
    "    if os.path.exists(real_path):\n",
    "        df2 = pd.read_csv(real_path, thousands=',')\n",
    "        df2 = df2[df2['代碼'] == _code_]\n",
    "        df2 = list( df2[df2['日期'] > date]['收盤價(元)'] )\n",
    "        print(format_n_days(df2) + '(real)')\n",
    "        print(TBrain_score(format_n_days(o4), format_n_days(df2)))\n",
    "    \n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
